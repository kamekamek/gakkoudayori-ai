# AIæ©Ÿèƒ½ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

å­¦æ ¡ã ã‚ˆã‚ŠAIã®ä¸­æ ¸ã¨ãªã‚‹AIå‡¦ç†ãƒ•ãƒ­ãƒ¼ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚éŸ³å£°å…¥åŠ›ã‹ã‚‰æœ€çµ‚çš„ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆã¾ã§ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°ã¨å®Ÿè£…æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ¯ å…¨ä½“ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[éŸ³å£°å…¥åŠ›] --> B[Speech-to-Text]
    B --> C[ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†]
    C --> D[Gemini AIå‡¦ç†]
    D --> E[HTMLç”Ÿæˆ]
    E --> F[ã‚¨ãƒ‡ã‚£ã‚¿è¡¨ç¤º]
    F --> G[PDFå‡ºåŠ›]
```

## ğŸ¤ Step 1: éŸ³å£°å…¥åŠ›

### å®Ÿè£…è©³ç´°

éŸ³å£°å…¥åŠ›ã¯ãƒ–ãƒ©ã‚¦ã‚¶ã®MediaRecorder APIã‚’ä½¿ç”¨ã—ã¦å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚

```dart
// lib/core/services/audio_service.dart
class AudioService {
  Future<void> startRecording() async {
    // ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯æ¨©é™ã‚’å–å¾—
    final stream = await window.navigator.mediaDevices.getUserMedia({
      'audio': true,
      'video': false,
    });
    
    // MediaRecorderã®åˆæœŸåŒ–
    _recorder = MediaRecorder(stream, {
      'mimeType': 'audio/webm',
      'audioBitsPerSecond': 128000,
    });
    
    // éŒ²éŸ³é–‹å§‹
    _recorder.start();
  }
}
```

### éŸ³å£°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- **å½¢å¼**: WebM (Opus codec)
- **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ**: 48kHz
- **ãƒ“ãƒƒãƒˆãƒ¬ãƒ¼ãƒˆ**: 128kbps
- **æœ€å¤§éŒ²éŸ³æ™‚é–“**: 5åˆ†

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- ãƒã‚¤ã‚¯æ¨©é™æ‹’å¦æ™‚ã®å‡¦ç†
- ãƒ–ãƒ©ã‚¦ã‚¶éå¯¾å¿œæ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
- éŒ²éŸ³ã‚¨ãƒ©ãƒ¼æ™‚ã®è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤

## ğŸ”¤ Step 2: Speech-to-Textå¤‰æ›

### Google Cloud Speech-to-Textè¨­å®š

```python
# backend/functions/speech_recognition_service.py
class SpeechRecognitionService:
    def __init__(self):
        self.client = speech.SpeechClient()
        self.config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
            sample_rate_hertz=48000,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            model="latest_long",
            use_enhanced=True,
        )
```

### éŸ³å£°èªè­˜ã®æœ€é©åŒ–

#### ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸ã®æ´»ç”¨
```python
# å­¦æ ¡ç‰¹æœ‰ã®ç”¨èªã‚’è¾æ›¸ã«è¿½åŠ 
speech_context = speech.SpeechContext(
    phrases=[
        "å­¦ç´šé€šä¿¡",
        "ä¿è­·è€…å„ä½",
        "é‹å‹•ä¼š",
        "ä¿®å­¦æ—…è¡Œ",
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç™»éŒ²ã—ãŸå˜èª
        *user_dictionary_words
    ],
    boost=20.0  # é‡è¦åº¦ã‚’é«˜ãè¨­å®š
)
```

#### ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ èªè­˜
```python
async def recognize_streaming(audio_stream):
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°èªè­˜"""
    streaming_config = speech.StreamingRecognitionConfig(
        config=self.config,
        interim_results=True,  # é€”ä¸­çµæœã‚’è¿”ã™
    )
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°èªè­˜ã®å®Ÿè¡Œ
    responses = client.streaming_recognize(
        streaming_config,
        audio_stream
    )
    
    for response in responses:
        for result in response.results:
            yield {
                'transcript': result.alternatives[0].transcript,
                'is_final': result.is_final,
                'confidence': result.alternatives[0].confidence
            }
```

## ğŸ¤– Step 3: Gemini AIã«ã‚ˆã‚‹æ–‡ç« æ•´å½¢

### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

```python
# backend/functions/gemini_api_service.py
class GeminiAPIService:
    def create_rewrite_prompt(self, text, style="formal"):
        """ãƒªãƒ©ã‚¤ãƒˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ"""
        prompt = f"""
ã‚ãªãŸã¯æ—¥æœ¬ã®å­¦æ ¡æ•™å¸«ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ–‡ç« ã‚’ã€å­¦ç´šé€šä¿¡ã«é©ã—ãŸå½¢ã«æ•´å½¢ã—ã¦ãã ã•ã„ã€‚

ã€åŸæ–‡ã€‘
{text}

ã€æ•´å½¢ãƒ«ãƒ¼ãƒ«ã€‘
1. æ•¬èªã‚’é©åˆ‡ã«ä½¿ç”¨ï¼ˆä¿è­·è€…å‘ã‘ã®ä¸å¯§ãªè¡¨ç¾ï¼‰
2. å¥èª­ç‚¹ã‚’é©åˆ‡ã«é…ç½®
3. æ®µè½ã‚’é©åˆ‡ã«åˆ†å‰²
4. è¦‹å‡ºã—ã‚’è‡ªå‹•ç”Ÿæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
5. æ•™è‚²çš„ãªé…æ…®ã‚’æŒã£ãŸè¡¨ç¾ã«èª¿æ•´

ã€æ–‡ä½“ã€‘
{self.get_style_instruction(style)}

ã€å‡ºåŠ›å½¢å¼ã€‘
æ•´å½¢ã•ã‚ŒãŸæ–‡ç« ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        return prompt
```

### ã‚¹ã‚¿ã‚¤ãƒ«ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³

```python
WRITING_STYLES = {
    "formal": "ä¸å¯§ã§æ ¼å¼ã®ã‚ã‚‹æ–‡ä½“",
    "friendly": "è¦ªã—ã¿ã‚„ã™ãæ¸©ã‹ã¿ã®ã‚ã‚‹æ–‡ä½“",
    "informative": "æƒ…å ±ã‚’åˆ†ã‹ã‚Šã‚„ã™ãä¼ãˆã‚‹æ–‡ä½“",
    "seasonal": "å­£ç¯€æ„Ÿã‚’å–ã‚Šå…¥ã‚ŒãŸæ–‡ä½“"
}
```

### AIå‡¦ç†ã®æœ€é©åŒ–

#### ãƒˆãƒ¼ã‚¯ãƒ³ç®¡ç†
```python
def optimize_prompt_tokens(self, text, max_tokens=2000):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æœ€é©åŒ–"""
    # ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã„å ´åˆã¯è¦ç´„ã—ã¦ã‹ã‚‰å‡¦ç†
    if self.count_tokens(text) > max_tokens:
        summary = self.summarize_text(text)
        return self.create_rewrite_prompt(summary)
    return self.create_rewrite_prompt(text)
```

#### ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
```python
async def generate_content_stream(self, prompt):
    """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
    response = await self.model.generate_content_async(
        prompt,
        stream=True,
        generation_config={
            "temperature": 0.7,
            "top_p": 0.95,
            "max_output_tokens": 2048,
        }
    )
    
    async for chunk in response:
        yield chunk.text
```

## ğŸ¨ Step 4: è¦‹å‡ºã—è‡ªå‹•ç”Ÿæˆ

### è¦‹å‡ºã—ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯

```python
def generate_headings(self, content):
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰é©åˆ‡ãªè¦‹å‡ºã—ã‚’ç”Ÿæˆ"""
    prompt = f"""
ä»¥ä¸‹ã®æ–‡ç« ã‹ã‚‰é©åˆ‡ãªè¦‹å‡ºã—ã‚’3-5å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€æ–‡ç« ã€‘
{content}

ã€è¦‹å‡ºã—ã®æ¡ä»¶ã€‘
- 10æ–‡å­—ä»¥å†…
- å†…å®¹ã‚’çš„ç¢ºã«è¡¨ç¾
- èª­è€…ã®èˆˆå‘³ã‚’å¼•ã
- å­¦ç´šé€šä¿¡ã«ãµã•ã‚ã—ã„

ã€å‡ºåŠ›å½¢å¼ã€‘
è¦‹å‡ºã—1: [è¦‹å‡ºã—]
è¦‹å‡ºã—2: [è¦‹å‡ºã—]
...
"""
    
    response = self.model.generate_content(prompt)
    return self.parse_headings(response.text)
```

### è¦‹å‡ºã—ã®ç¨®é¡

1. **ã‚¤ãƒ™ãƒ³ãƒˆå‹**: ã€Œé‹å‹•ä¼šã®ãŠçŸ¥ã‚‰ã›ã€ã€Œä¿®å­¦æ—…è¡Œãƒ¬ãƒãƒ¼ãƒˆã€
2. **é€£çµ¡å‹**: ã€Œæ¥é€±ã®äºˆå®šã€ã€ŒæŒã¡ç‰©ã®ãŠé¡˜ã„ã€
3. **å ±å‘Šå‹**: ã€Œå­¦ç¿’ã®æ§˜å­ã€ã€Œã‚¯ãƒ©ã‚¹ã®æˆé•·ã€
4. **å­£ç¯€å‹**: ã€Œæ˜¥ã®è¨ªã‚Œã€ã€Œå¤ä¼‘ã¿ã«å‘ã‘ã¦ã€

## ğŸ“ Step 5: HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ

### ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚·ã‚¹ãƒ†ãƒ 

```python
class LayoutGenerator:
    def generate_html(self, content, layout_type="standard"):
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰HTMLã‚’ç”Ÿæˆ"""
        template = self.get_template(layout_type)
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†å‰²
        sections = self.split_into_sections(content)
        
        # HTMLç”Ÿæˆ
        html_parts = []
        for section in sections:
            html_parts.append(
                self.render_section(section, template)
            )
        
        return self.wrap_in_layout(html_parts, template)
```

### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç¨®é¡

```python
LAYOUT_TEMPLATES = {
    "standard": {
        "columns": 1,
        "image_position": "inline",
        "font_size": "medium"
    },
    "image_heavy": {
        "columns": 2,
        "image_position": "grid",
        "font_size": "small"
    },
    "text_only": {
        "columns": 1,
        "image_position": "none",
        "font_size": "large"
    },
    "magazine": {
        "columns": 2,
        "image_position": "mixed",
        "font_size": "medium"
    }
}
```

## ğŸ”„ Step 6: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤

### å …ç‰¢ãªã‚¨ãƒ©ãƒ¼å‡¦ç†

```python
class AIWorkflowOrchestrator:
    async def process_with_retry(self, audio_data, max_retries=3):
        """ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãå‡¦ç†"""
        for attempt in range(max_retries):
            try:
                # éŸ³å£°èªè­˜
                text = await self.speech_to_text(audio_data)
                
                # AIå‡¦ç†
                refined_text = await self.refine_with_ai(text)
                
                # HTMLç”Ÿæˆ
                html = await self.generate_html(refined_text)
                
                return {
                    "success": True,
                    "data": {
                        "original_text": text,
                        "refined_text": refined_text,
                        "html": html
                    }
                }
                
            except Exception as e:
                if attempt == max_retries - 1:
                    return {
                        "success": False,
                        "error": str(e),
                        "fallback": self.get_fallback_response()
                    }
                
                # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
                await asyncio.sleep(2 ** attempt)
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### å‡¦ç†æ™‚é–“ã®ç›®æ¨™

| å‡¦ç† | ç›®æ¨™æ™‚é–“ | ç¾åœ¨ã®å®Ÿç¸¾ |
|------|----------|------------|
| éŸ³å£°èªè­˜ï¼ˆ30ç§’ï¼‰ | < 2ç§’ | 1.5ç§’ |
| AIæ•´å½¢ | < 3ç§’ | 2.8ç§’ |
| HTMLç”Ÿæˆ | < 1ç§’ | 0.5ç§’ |
| å…¨ä½“ | < 6ç§’ | 4.8ç§’ |

### ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥

```python
# é »å‡ºãƒ•ãƒ¬ãƒ¼ã‚ºã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
PHRASE_CACHE = {
    "greeting": {
        "æ˜¥": "æ˜¥ã®è¨ªã‚Œã¨ã¨ã‚‚ã«ã€æ–°ã—ã„å­¦æœŸãŒå§‹ã¾ã‚Šã¾ã—ãŸã€‚",
        "å¤": "æš‘ã„æ—¥ãŒç¶šãã¾ã™ãŒã€å­ã©ã‚‚ãŸã¡ã¯å…ƒæ°—ã„ã£ã±ã„ã§ã™ã€‚",
        "ç§‹": "å®Ÿã‚Šã®ç§‹ã‚’è¿ãˆã€å­¦ç¿’ã‚‚æ·±ã¾ã£ã¦ãã¾ã—ãŸã€‚",
        "å†¬": "å¯’ã•ãŒå³ã—ããªã£ã¦ãã¾ã—ãŸãŒã€æ¸©ã‹ã„æ•™å®¤ã§å­¦ã‚“ã§ã„ã¾ã™ã€‚"
    }
}
```

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆä¾‹

```python
# test_ai_workflow.py
class TestAIWorkflow:
    def test_speech_recognition_accuracy(self):
        """éŸ³å£°èªè­˜ç²¾åº¦ã®ãƒ†ã‚¹ãƒˆ"""
        test_audio = load_test_audio("sample_teacher_voice.webm")
        expected_text = "ä»Šæ—¥ã¯é‹å‹•ä¼šã®ç·´ç¿’ã‚’ã—ã¾ã—ãŸ"
        
        result = speech_service.recognize(test_audio)
        similarity = calculate_similarity(result, expected_text)
        
        assert similarity > 0.95  # 95%ä»¥ä¸Šã®ç²¾åº¦
```

### çµ±åˆãƒ†ã‚¹ãƒˆ

```python
async def test_end_to_end_workflow():
    """ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
    # ãƒ†ã‚¹ãƒˆéŸ³å£°ãƒ‡ãƒ¼ã‚¿
    audio_data = create_test_audio_data()
    
    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ
    result = await orchestrator.process_workflow(audio_data)
    
    # æ¤œè¨¼
    assert result["success"] is True
    assert "html" in result["data"]
    assert len(result["data"]["html"]) > 100
```

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### ãƒ‡ãƒ¼ã‚¿ä¿è­·

1. **éŸ³å£°ãƒ‡ãƒ¼ã‚¿**: å‡¦ç†å¾Œå³å‰Šé™¤
2. **ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿**: æš—å·åŒ–ã—ã¦ä¿å­˜
3. **å€‹äººæƒ…å ±**: è‡ªå‹•ãƒã‚¹ã‚­ãƒ³ã‚°å‡¦ç†

### APIã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

```python
# ãƒ¬ãƒ¼ãƒˆåˆ¶é™
@rate_limit(calls=10, period=60)  # 1åˆ†é–“ã«10å›ã¾ã§
async def process_audio(request):
    # èªè¨¼ãƒã‚§ãƒƒã‚¯
    if not await verify_auth_token(request.headers):
        raise HTTPException(401, "Unauthorized")
    
    # å‡¦ç†å®Ÿè¡Œ
    return await ai_workflow.process(request.data)
```

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [Google Cloud Speech-to-Text ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://cloud.google.com/speech-to-text/docs)
- [Vertex AI Gemini API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini)
- [ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/prompts/introduction-prompt-design)

---

*æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: [ã‚¨ãƒ‡ã‚£ã‚¿æ©Ÿèƒ½](editing.md)ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç·¨é›†ã®è©³ç´°ã‚’å­¦ã¶*