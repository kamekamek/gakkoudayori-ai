# ADK Workflowã‚¬ã‚¤ãƒ‰

## ğŸ“‹ æ¦‚è¦

Google ADK Workflowã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆSequential, Parallelï¼‰ã‚’æ´»ç”¨ã—ãŸåŠ¹ç‡çš„ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã‚¬ã‚¤ãƒ‰ã€‚å­¦ç´šé€šä¿¡ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹æœ€é©ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­è¨ˆã¨å®Ÿè£…æ–¹æ³•ã‚’è§£èª¬ã€‚

## ğŸ¯ Workflowã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç¨®é¡

### 1. Sequential Workflow
**ç‰¹å¾´:** é †æ¬¡å®Ÿè¡Œã€å‰ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµæœã‚’æ¬¡ã«æ¸¡ã™  
**é©ç”¨å ´é¢:** ä¾å­˜é–¢ä¿‚ã®ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã€æ®µéšçš„å‡¦ç†

### 2. Parallel Workflow  
**ç‰¹å¾´:** ä¸¦è¡Œå®Ÿè¡Œã€åŒæ™‚å‡¦ç†ã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š  
**é©ç”¨å ´é¢:** ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã€æ™‚é–“çŸ­ç¸®ãŒå¿…è¦ãªå‡¦ç†

### 3. Loop Workflow
**ç‰¹å¾´:** åå¾©å®Ÿè¡Œã€æ¡ä»¶ã«åŸºã¥ãç¹°ã‚Šè¿”ã—å‡¦ç†  
**é©ç”¨å ´é¢:** å“è³ªæ”¹å–„ã€å‹•çš„ãªå‡¦ç†å›æ•°

---

## ğŸ—ï¸ å­¦ç´šé€šä¿¡ã‚·ã‚¹ãƒ†ãƒ ã§ã®Workflowè¨­è¨ˆ

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

```
NewsletterADKOrchestrator
â”œâ”€â”€ Sequential Workflows
â”‚   â”œâ”€â”€ content_to_html_flow     # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„â†’HTMLç”Ÿæˆ
â”‚   â”œâ”€â”€ quality_improvement_flow # å“è³ªæ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹
â”‚   â””â”€â”€ full_generation_flow     # å®Œå…¨ç”Ÿæˆãƒ•ãƒ­ãƒ¼
â”œâ”€â”€ Parallel Workflows
â”‚   â”œâ”€â”€ content_design_parallel  # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³ä¸¦è¡Œ
â”‚   â”œâ”€â”€ phase2_enhancement      # Phase2æ©Ÿèƒ½ä¸¦è¡Œå‡¦ç†
â”‚   â””â”€â”€ validation_parallel     # ä¸¦è¡Œå“è³ªæ¤œè¨¼
â””â”€â”€ Hybrid Workflows
    â”œâ”€â”€ optimized_generation    # Sequential + Parallelçµ„ã¿åˆã‚ã›
    â””â”€â”€ error_recovery_flow     # ã‚¨ãƒ©ãƒ¼å›å¾©ãƒ•ãƒ­ãƒ¼
```

---

## ğŸ“ Workflowå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³

### 1. åŸºæœ¬Sequentialå‡¦ç†

#### `content_to_html_flow`
```python
self.workflows['content_to_html_flow'] = Sequential([
    self.agents['content_writer'],      # 1. æ–‡ç« ç”Ÿæˆ
    self.agents['design_specialist'],   # 2. ãƒ‡ã‚¶ã‚¤ãƒ³è¨­è¨ˆ
    self.agents['html_developer'],      # 3. HTMLç”Ÿæˆ
    self.agents['quality_manager']      # 4. å“è³ªæ¤œè¨¼
])
```

**å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
```
éŸ³å£°å…¥åŠ› â†’ [content_writer] â†’ æ–‡ç« 
æ–‡ç«  â†’ [design_specialist] â†’ ãƒ‡ã‚¶ã‚¤ãƒ³ä»•æ§˜
æ–‡ç« +ãƒ‡ã‚¶ã‚¤ãƒ³ â†’ [html_developer] â†’ HTML
HTML+æ–‡ç«  â†’ [quality_manager] â†’ å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- ç¢ºå®Ÿãªä¾å­˜é–¢ä¿‚å‡¦ç†
- ãƒ‡ãƒãƒƒã‚°ã—ã‚„ã™ã„
- ã‚¨ãƒ©ãƒ¼ç®‡æ‰€ã®ç‰¹å®šãŒå®¹æ˜“

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ:**
- å‡¦ç†æ™‚é–“ãŒé•·ã„
- ä¸¦è¡Œå‡¦ç†ã®æ©æµãªã—

### 2. åŸºæœ¬Parallelå‡¦ç†

#### `content_design_parallel`
```python
self.workflows['content_design_parallel'] = Parallel([
    self.agents['content_writer'],    # æ–‡ç« ç”Ÿæˆ
    self.agents['design_specialist']  # ãƒ‡ã‚¶ã‚¤ãƒ³è¨­è¨ˆï¼ˆç‹¬ç«‹ï¼‰
])
```

**å‡¦ç†ãƒ•ãƒ­ãƒ¼:**
```
éŸ³å£°å…¥åŠ› â†’ â”Œâ”€ [content_writer] â†’ æ–‡ç« 
           â””â”€ [design_specialist] â†’ åŸºæœ¬ãƒ‡ã‚¶ã‚¤ãƒ³ä»•æ§˜
```

**å®Ÿè£…ä¾‹:**
```python
async def execute_parallel_content_design(self, audio_transcript: str, grade_level: str):
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãƒ‡ã‚¶ã‚¤ãƒ³ã®ä¸¦è¡Œç”Ÿæˆ"""
    
    # ä¸¦è¡Œã‚¿ã‚¹ã‚¯å®šç¾©
    parallel_tasks = {
        'content_generation': {
            'agent': 'content_writer',
            'params': {
                'audio_transcript': audio_transcript,
                'grade_level': grade_level,
                'content_type': 'newsletter'
            }
        },
        'design_generation': {
            'agent': 'design_specialist', 
            'params': {
                'content': audio_transcript,  # åˆæœŸæ®µéšã§ã¯éŸ³å£°å†…å®¹ä½¿ç”¨
                'theme': 'seasonal',
                'grade_level': grade_level
            }
        }
    }
    
    # ä¸¦è¡Œå®Ÿè¡Œ
    results = await self._execute_parallel_workflow(
        'content_design_parallel',
        parallel_tasks
    )
    
    return results
```

### 3. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å‡¦ç†ï¼ˆæ¨å¥¨ï¼‰

#### `optimized_generation_flow`
```python
class OptimizedGenerationWorkflow:
    """Sequential + Parallelçµ„ã¿åˆã‚ã›ã«ã‚ˆã‚‹æœ€é©åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    async def execute(self, input_data: dict) -> dict:
        # Phase 1: ä¸¦è¡Œå‡¦ç†ï¼ˆç‹¬ç«‹ã‚¿ã‚¹ã‚¯ï¼‰
        parallel_results = await self.parallel_phase(input_data)
        
        # Phase 2: é †æ¬¡å‡¦ç†ï¼ˆä¾å­˜é–¢ä¿‚ã‚ã‚Šï¼‰
        sequential_results = await self.sequential_phase(parallel_results)
        
        # Phase 3: ä¸¦è¡Œå‡¦ç†ï¼ˆæœ€çµ‚åŒ–ï¼‰
        final_results = await self.final_parallel_phase(sequential_results)
        
        return self.combine_results([
            parallel_results,
            sequential_results, 
            final_results
        ])
```

**å‡¦ç†ãƒ•ãƒ­ãƒ¼å›³:**
```
éŸ³å£°å…¥åŠ›
    â†“
Phase 1 (Parallel):
    â”œâ”€ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    â””â”€ åŸºæœ¬ãƒ‡ã‚¶ã‚¤ãƒ³
    â†“
Phase 2 (Sequential):
    HTMLç”Ÿæˆ â†’ å“è³ªæ¤œè¨¼
    â†“
Phase 3 (Parallel):
    â”œâ”€ PDFç”Ÿæˆ
    â”œâ”€ ç”»åƒè¿½åŠ 
    â””â”€ Classroomæº–å‚™
    â†“
å®Œæˆå“
```

---

## ğŸ”§ Phase 2çµ±åˆWorkflow

### `full_automation_workflow`

```python
class FullAutomationWorkflow:
    """éŸ³å£°å…¥åŠ›ã‹ã‚‰Classroomé…å¸ƒã¾ã§ã®å®Œå…¨è‡ªå‹•åŒ–"""
    
    def __init__(self):
        self.phase1_agents = ['content_writer', 'design_specialist']
        self.phase2_agents = ['html_developer', 'quality_manager']
        self.phase3_agents = ['pdf_output', 'media_enhancer', 'classroom_integrator']
    
    async def execute_full_automation(
        self,
        audio_transcript: str,
        options: dict
    ) -> dict:
        """å®Œå…¨è‡ªå‹•åŒ–ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        
        start_time = time.time()
        results = {}
        
        try:
            # Stage 1: åŸºç¤ç”Ÿæˆï¼ˆä¸¦è¡Œï¼‰
            logger.info("Stage 1: Parallel content and design generation")
            stage1_results = await self._execute_stage1_parallel(
                audio_transcript, options
            )
            results['stage1'] = stage1_results
            
            # Stage 2: HTMLç”Ÿæˆãƒ»å“è³ªç¢ºèªï¼ˆé †æ¬¡ï¼‰
            logger.info("Stage 2: Sequential HTML generation and validation")
            stage2_results = await self._execute_stage2_sequential(
                stage1_results, options
            )
            results['stage2'] = stage2_results
            
            # Stage 3: æœ€çµ‚å‡ºåŠ›å‡¦ç†ï¼ˆä¸¦è¡Œï¼‰
            logger.info("Stage 3: Parallel final output processing")
            stage3_results = await self._execute_stage3_parallel(
                stage2_results, options
            )
            results['stage3'] = stage3_results
            
            # çµæœçµ±åˆ
            final_result = self._combine_all_results(results)
            final_result['processing_time'] = time.time() - start_time
            
            return final_result
            
        except Exception as e:
            logger.error(f"Full automation workflow failed: {e}")
            return self._handle_workflow_error(e, results)
```

### Stageåˆ¥å®Ÿè£…è©³ç´°

#### Stage 1: ä¸¦è¡ŒåŸºç¤ç”Ÿæˆ
```python
async def _execute_stage1_parallel(self, audio_transcript: str, options: dict):
    """Stage 1: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³ä¸¦è¡Œç”Ÿæˆ"""
    
    parallel_tasks = {
        'content_writer': {
            'audio_transcript': audio_transcript,
            'grade_level': options.get('grade_level', '3å¹´1çµ„'),
            'content_type': 'newsletter'
        },
        'design_specialist': {
            'content': audio_transcript,  # åˆæœŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„
            'theme': options.get('theme', 'seasonal'),
            'grade_level': options.get('grade_level', '3å¹´1çµ„')
        }
    }
    
    # ä¸¦è¡Œå®Ÿè¡Œï¼ˆç´„50%æ™‚é–“çŸ­ç¸®ï¼‰
    results = await asyncio.gather(
        self._execute_agent_task('content_writer', parallel_tasks['content_writer']),
        self._execute_agent_task('design_specialist', parallel_tasks['design_specialist']),
        return_exceptions=True
    )
    
    return {
        'content_result': results[0],
        'design_result': results[1],
        'stage_duration': time.time() - stage_start
    }
```

#### Stage 2: é †æ¬¡HTMLç”Ÿæˆ
```python
async def _execute_stage2_sequential(self, stage1_results: dict, options: dict):
    """Stage 2: HTMLç”Ÿæˆãƒ»å“è³ªæ¤œè¨¼ï¼ˆä¾å­˜é–¢ä¿‚ã‚ã‚Šï¼‰"""
    
    content_result = stage1_results['content_result']
    design_result = stage1_results['design_result']
    
    # HTMLç”Ÿæˆï¼ˆå‰æ®µçµæœã«ä¾å­˜ï¼‰
    html_result = await self._execute_agent_task('html_developer', {
        'content': content_result.get('content', ''),
        'design_spec': design_result.get('design_spec', {}),
        'template_type': options.get('template_type', 'newsletter')
    })
    
    # å“è³ªæ¤œè¨¼ï¼ˆHTMLçµæœã«ä¾å­˜ï¼‰
    quality_result = await self._execute_agent_task('quality_manager', {
        'html_content': html_result.get('html', ''),
        'original_content': content_result.get('content', '')
    })
    
    return {
        'html_result': html_result,
        'quality_result': quality_result,
        'stage_duration': time.time() - stage_start
    }
```

#### Stage 3: ä¸¦è¡Œæœ€çµ‚å‡¦ç†
```python
async def _execute_stage3_parallel(self, stage2_results: dict, options: dict):
    """Stage 3: PDFãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»Classroomä¸¦è¡Œå‡¦ç†"""
    
    html_content = stage2_results['html_result'].get('html', '')
    
    # ä¸¦è¡Œã‚¿ã‚¹ã‚¯å®šç¾©
    parallel_tasks = []
    
    if options.get('enable_pdf', True):
        parallel_tasks.append(
            self._execute_agent_task('pdf_output', {
                'html_content': html_content,
                'newsletter_metadata': self._build_metadata(options),
                'pdf_options': options.get('pdf_options', {})
            })
        )
    
    if options.get('enable_images', True):
        parallel_tasks.append(
            self._execute_agent_task('media_enhancer', {
                'html_content': html_content,
                'newsletter_data': self._build_newsletter_data(options),
                'media_options': options.get('media_options', {})
            })
        )
    
    if options.get('classroom_settings'):
        # PDFç”Ÿæˆå®Œäº†å¾Œã«Classroomé…å¸ƒï¼ˆæ¡ä»¶ä»˜ãä¸¦è¡Œï¼‰
        parallel_tasks.append(
            self._conditional_classroom_distribution(options)
        )
    
    # ä¸¦è¡Œå®Ÿè¡Œ
    results = await asyncio.gather(*parallel_tasks, return_exceptions=True)
    
    return {
        'pdf_result': results[0] if len(results) > 0 else None,
        'media_result': results[1] if len(results) > 1 else None,
        'classroom_result': results[2] if len(results) > 2 else None,
        'stage_duration': time.time() - stage_start
    }
```

---

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ä¸¦è¡Œå‡¦ç†ã«ã‚ˆã‚‹æ™‚é–“çŸ­ç¸®

**å¾“æ¥ã®Sequentialå‡¦ç†:**
```
ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ: 8ç§’
+ ãƒ‡ã‚¶ã‚¤ãƒ³ç”Ÿæˆ: 5ç§’  
+ HTMLç”Ÿæˆ: 6ç§’
+ å“è³ªæ¤œè¨¼: 3ç§’
= åˆè¨ˆ: 22ç§’
```

**æœ€é©åŒ–Workflow:**
```
Stage 1 (ä¸¦è¡Œ): max(8ç§’, 5ç§’) = 8ç§’
Stage 2 (é †æ¬¡): 6ç§’ + 3ç§’ = 9ç§’
Stage 3 (ä¸¦è¡Œ): max(4ç§’, 6ç§’, 3ç§’) = 6ç§’
= åˆè¨ˆ: 23ç§’ â†’ ç´„35%çŸ­ç¸®
```

### 2. ã‚¨ãƒ©ãƒ¼è€æ€§ã®å‘ä¸Š

```python
class ResilientWorkflow:
    """ã‚¨ãƒ©ãƒ¼å›å¾©æ©Ÿèƒ½ä»˜ããƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    async def execute_with_fallback(self, input_data: dict):
        try:
            # æœ€é©åŒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è©¦è¡Œ
            return await self.optimized_workflow(input_data)
            
        except ParallelProcessingError:
            logger.warning("Parallel processing failed, falling back to sequential")
            return await self.sequential_fallback(input_data)
            
        except CriticalAgentError as e:
            logger.error(f"Critical agent failed: {e.agent_name}")
            return await self.partial_generation_with_alternatives(input_data, e)
```

### 3. å‹•çš„è² è·åˆ†æ•£

```python
class AdaptiveWorkflow:
    """ã‚·ã‚¹ãƒ†ãƒ è² è·ã«å¿œã˜ãŸå‹•çš„ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é¸æŠ"""
    
    async def execute_adaptive(self, input_data: dict):
        # ã‚·ã‚¹ãƒ†ãƒ è² è·è©•ä¾¡
        load_metrics = await self.assess_system_load()
        
        if load_metrics['cpu_usage'] > 80:
            # é«˜è² è·æ™‚ï¼šSequentialå‡¦ç†
            return await self.sequential_workflow(input_data)
        elif load_metrics['available_memory'] > 2048:
            # ååˆ†ãªãƒªã‚½ãƒ¼ã‚¹ï¼šæœ€å¤§ä¸¦è¡Œå‡¦ç†
            return await self.maximum_parallel_workflow(input_data)
        else:
            # é€šå¸¸ï¼šãƒãƒ©ãƒ³ã‚¹å‹
            return await self.balanced_workflow(input_data)
```

---

## ğŸ§ª Workflowãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 1. å˜ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ

```python
class TestWorkflows:
    
    @pytest.mark.asyncio
    async def test_sequential_workflow(self):
        """Sequentialå‡¦ç†ã®å‹•ä½œç¢ºèª"""
        workflow = SequentialWorkflow([
            MockAgent('agent1'),
            MockAgent('agent2'),
            MockAgent('agent3')
        ])
        
        result = await workflow.execute({'input': 'test'})
        
        assert result['status'] == 'success'
        assert len(result['steps']) == 3
        assert result['execution_order'] == ['agent1', 'agent2', 'agent3']
    
    @pytest.mark.asyncio
    async def test_parallel_workflow(self):
        """Parallelå‡¦ç†ã®å‹•ä½œç¢ºèª"""
        workflow = ParallelWorkflow([
            MockAgent('agent1', delay=2),
            MockAgent('agent2', delay=3),
            MockAgent('agent3', delay=1)
        ])
        
        start_time = time.time()
        result = await workflow.execute({'input': 'test'})
        execution_time = time.time() - start_time
        
        assert result['status'] == 'success'
        assert execution_time < 4  # æœ€é•·ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ™‚é–“ä»¥ä¸‹
        assert len(result['parallel_results']) == 3
```

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ

```python
@pytest.mark.asyncio
async def test_workflow_error_handling(self):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å†…ã‚¨ãƒ©ãƒ¼ã®é©åˆ‡ãªå‡¦ç†"""
    
    # ä¸€éƒ¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¤±æ•—ã‚·ãƒŠãƒªã‚ª
    workflow = ParallelWorkflow([
        MockAgent('success_agent'),
        MockAgent('failure_agent', should_fail=True),
        MockAgent('slow_agent', delay=10)
    ])
    
    result = await workflow.execute({'input': 'test'})
    
    assert result['status'] == 'partial_success'
    assert 'success_agent' in result['successful_agents']
    assert 'failure_agent' in result['failed_agents']
    assert result['error_recovery_applied'] == True
```

### 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

```python
@pytest.mark.asyncio
async def test_workflow_performance(self):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ€§èƒ½è¦ä»¶ã®ç¢ºèª"""
    
    performance_targets = {
        'sequential': 30,    # 30ç§’ä»¥å†…
        'parallel': 20,      # 20ç§’ä»¥å†…
        'hybrid': 15         # 15ç§’ä»¥å†…
    }
    
    for workflow_type, target_time in performance_targets.items():
        start_time = time.time()
        result = await self.execute_workflow(workflow_type, test_input)
        execution_time = time.time() - start_time
        
        assert result['status'] == 'success'
        assert execution_time < target_time
        assert result['quality_score'] > 80
```

---

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### 1. Workflowå®Ÿè¡Œãƒ¡ãƒˆãƒªã‚¯ã‚¹

```python
class WorkflowMetrics:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡ŒçŠ¶æ³ã®ç›£è¦–"""
    
    def collect_metrics(self, workflow_result: dict):
        return {
            'execution_time': workflow_result.get('processing_time', 0),
            'success_rate': self.calculate_success_rate(workflow_result),
            'agent_performance': self.analyze_agent_performance(workflow_result),
            'bottleneck_analysis': self.identify_bottlenecks(workflow_result),
            'resource_utilization': self.measure_resource_usage(workflow_result)
        }
    
    def generate_performance_report(self, metrics_history: list):
        """æ€§èƒ½ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        return {
            'average_execution_time': statistics.mean([m['execution_time'] for m in metrics_history]),
            'success_rate_trend': self.calculate_trend([m['success_rate'] for m in metrics_history]),
            'performance_degradation_alerts': self.detect_performance_issues(metrics_history),
            'optimization_recommendations': self.suggest_optimizations(metrics_history)
        }
```

### 2. ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

```python
class WorkflowAlerts:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç•°å¸¸ã®æ¤œå‡ºãƒ»é€šçŸ¥"""
    
    def monitor_workflow_health(self, metrics: dict):
        alerts = []
        
        if metrics['execution_time'] > self.thresholds['max_execution_time']:
            alerts.append({
                'type': 'PERFORMANCE_DEGRADATION',
                'severity': 'WARNING',
                'message': f"å®Ÿè¡Œæ™‚é–“ãŒé–¾å€¤ã‚’è¶…é: {metrics['execution_time']:.2f}ç§’"
            })
        
        if metrics['success_rate'] < self.thresholds['min_success_rate']:
            alerts.append({
                'type': 'SUCCESS_RATE_LOW',
                'severity': 'CRITICAL',
                'message': f"æˆåŠŸç‡ãŒä½ä¸‹: {metrics['success_rate']:.1%}"
            })
        
        return alerts
```

---

## ğŸ”§ å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Workflowè¨­è¨ˆ
- [ ] ä¾å­˜é–¢ä¿‚ã®æ˜ç¢ºåŒ–
- [ ] ä¸¦è¡Œå‡¦ç†å¯èƒ½éƒ¨åˆ†ã®ç‰¹å®š
- [ ] ã‚¨ãƒ©ãƒ¼å›å¾©æˆ¦ç•¥ã®å®šç¾©
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™ã®è¨­å®š

### å®Ÿè£…
- [ ] SequentialWorkflowã®å®Ÿè£…
- [ ] ParallelWorkflowã®å®Ÿè£…
- [ ] ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®å®Ÿè£…
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®çµ±åˆ

### ãƒ†ã‚¹ãƒˆ
- [ ] å˜ä½“ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ
- [ ] çµ±åˆãƒ†ã‚¹ãƒˆ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
- [ ] ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ

### ç›£è¦–
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®å®Ÿè£…
- [ ] ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š
- [ ] ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æ§‹ç¯‰
- [ ] å®šæœŸãƒ¬ãƒãƒ¼ãƒˆã®è‡ªå‹•åŒ–

---

**ğŸ“… ã‚¬ã‚¤ãƒ‰ä½œæˆæ—¥:** 2024å¹´6æœˆ19æ—¥  
**ğŸ“ æœ€çµ‚æ›´æ–°æ—¥:** 2024å¹´6æœˆ19æ—¥  
**ğŸ‘¤ ä½œæˆè€…:** Claude Code AI Assistant  
**ğŸ“‹ ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** v1.0.0